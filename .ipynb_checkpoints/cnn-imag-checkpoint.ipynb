{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:20:06.753455Z",
     "iopub.status.busy": "2023-11-27T17:20:06.753065Z",
     "iopub.status.idle": "2023-11-27T17:20:20.857018Z",
     "shell.execute_reply": "2023-11-27T17:20:20.856039Z",
     "shell.execute_reply.started": "2023-11-27T17:20:06.753424Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:20:27.719812Z",
     "iopub.status.busy": "2023-11-27T17:20:27.719414Z",
     "iopub.status.idle": "2023-11-27T17:20:39.745192Z",
     "shell.execute_reply": "2023-11-27T17:20:39.744320Z",
     "shell.execute_reply.started": "2023-11-27T17:20:27.719779Z"
    }
   },
   "outputs": [],
   "source": [
    "#Librerias básicas\n",
    "#================================================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import duckdb\n",
    "import glob\n",
    "\n",
    "# Configuración para machine learning\n",
    "# ================================================================================\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Activar SQL en Python\n",
    "# ================================================================================\n",
    "con = duckdb.connect(database=':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:20:43.965835Z",
     "iopub.status.busy": "2023-11-27T17:20:43.965176Z",
     "iopub.status.idle": "2023-11-27T17:20:43.970777Z",
     "shell.execute_reply": "2023-11-27T17:20:43.969834Z",
     "shell.execute_reply.started": "2023-11-27T17:20:43.965802Z"
    }
   },
   "outputs": [],
   "source": [
    "#Url Ari \n",
    "url_lcc    = \"C:/Users/ASUS/OneDrive/Documentos/2023-2/Inteligencia/Proyecto/Exoplanet-detection-with-Neural-Network/Curvas_de_luz_cor/\"\n",
    "url_lc_img = \"/kaggle/input/division-datos-img/\"\n",
    "url_img = \"/kaggle/input/division-datos-img/\"\n",
    "url        = \"C:/Users/ASUS/OneDrive/Documentos/2023-2/Inteligencia/Proyecto/Exoplanet-detection-with-Neural-Network/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Urls Pater\n",
    "url_lcc    = \"/home/pater/Desktop/CosasPater/UNAL/2023-02NovenoSemestre/Exoplanet-detection-with-Neural-Network/Curvas_de_luz_cor/\"\n",
    "url_lc_img = \"/home/pater/Desktop/CosasPater/UNAL/2023-02NovenoSemestre/ClassificationExoplanets/Curvas_de_luz_img/\"\n",
    "url_img = \"/home/pater/Desktop/CosasPater/UNAL/2023-02NovenoSemestre/ClassificationExoplanets/\"\n",
    "url        = \"/home/pater/Desktop/CosasPater/UNAL/2023-02NovenoSemestre/Exoplanet-detection-with-Neural-Network/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carac_Stars = pd.read_csv(url+\"Carac_Stars.csv\")\n",
    "Carac_Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = os.listdir(url_lcc) \n",
    "arch.sort()\n",
    "Stars_list = [star[3:-4] for star in arch]\n",
    "\n",
    "s_flux  = []\n",
    "s_err   = []\n",
    "Id_real = []\n",
    "for Str in arch:\n",
    "    serie = pd.read_csv(url_lcc+Str).set_index('time')\n",
    "    s_flux.append(np.array(serie['flux']))\n",
    "    s_err.append(np.array(serie['flux_err']))\n",
    "    Id_real.append(Str[3:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stars = pd.DataFrame()\n",
    "Stars[\"ID\"] = Id_real\n",
    "Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clas_Stars = con.execute(\"\"\"select S.ID, case when C.Clasificacion == 'CANDIDATE' then 1 \n",
    "                                              else 0             \n",
    "                                         end as ClasBin\n",
    "                            from Carac_Stars C inner join Stars S on (S.ID = C.Kepler_ID)\n",
    "                            order by S.ID\"\"\").df()\n",
    "Clas_Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtención de las imagenes ya existentes en la carpeta\n",
    "contenido = os.listdir(url_lc_img)\n",
    "L_Str = []\n",
    "for Str in contenido:\n",
    "    Str = Str[4:-4]\n",
    "    L_Str.append(Str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se descargan las curvas de luz no existentes\n",
    "KEPID = list(Stars['ID'])\n",
    "i = 0\n",
    "for name in KEPID:\n",
    "    if name in L_Str:\n",
    "        i += 1\n",
    "        continue\n",
    "    else:\n",
    "        j = KEPID.index(name)\n",
    "        name = int(name)\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(s_flux[j],color=\"#000000\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_lc_img}Img_{name}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 300\n",
    "name = \"Prueba\"\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(s_flux[j],color=\"#000000\")\n",
    "plt.axis('off')\n",
    "plt.savefig(f\"{url_lc_img}Img_{name}\", dpi=72, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División conjuntos train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido = os.listdir(url_lc_img)\n",
    "Img_LC = []\n",
    "i = 0\n",
    "for img in contenido:\n",
    "    i += 1\n",
    "    #Se obtienen las imagenes normalizadas en escala de grises\n",
    "    Img = cv2.imread(url_lc_img+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    Img_LC.append(Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenar las imágenes y sus respectivos labels\n",
    "list_img = os.listdir(url_lc_img)\n",
    "for i in range(len(list_img)):\n",
    "    Str = list_img[i][4:-4]\n",
    "    list_img[i] = Str\n",
    "\n",
    "# obtención de labels correspondientes a cada imagen\n",
    "Clas_Stars['ID'] = pd.Categorical(Clas_Stars['ID'], categories=list_img, ordered=True)\n",
    "Labels = np.array(Clas_Stars.sort_values('ID')['ClasBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División entrenamiento, validación y prueba\n",
    "Img_train, Img_test, Labs_train, Labs_test = train_test_split(\n",
    "    Img_LC, Labels, test_size=0.3, random_state=13)\n",
    "\n",
    "Img_val, Img_test, Labs_val, Labs_test = train_test_split(\n",
    "    Img_test, Labs_test, test_size=0.33333333333333333, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estrellas con exoplanetas en train: \",len(Labs_train[Labs_train==1]))\n",
    "print(\"Estrellas sin exoplanetas en train: \",len(Labs_train[Labs_train==0]))\n",
    "print(\"Estrellas con exoplanetas en val: \",len(Labs_val[Labs_val==1]))\n",
    "print(\"Estrellas sin exoplanetas en val: \",len(Labs_val[Labs_val==0]))\n",
    "print(\"Estrellas con exoplanetas en test: \",len(Labs_test[Labs_test==1]))\n",
    "print(\"Estrellas sin exoplanetas en test: \",len(Labs_test[Labs_test==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Img_train)):\n",
    "    if Labs_train[i]==1:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_train[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Train_img/1/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    elif Labs_train[i]==0:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_train[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Train_img/0/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Img_val)):\n",
    "    if Labs_val[i]==1:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_val[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Val_img/1/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    elif Labs_val[i]==0:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_val[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Val_img/0/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Img_test)):\n",
    "    if Labs_test[i]==1:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_test[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Test_img/1/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    elif Labs_test[i]==0:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(Img_test[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{url_img}Test_img/0/{i}\", dpi=72, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de redes convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:21:03.617445Z",
     "iopub.status.busy": "2023-11-27T17:21:03.616382Z",
     "iopub.status.idle": "2023-11-27T17:21:50.401553Z",
     "shell.execute_reply": "2023-11-27T17:21:50.400522Z",
     "shell.execute_reply.started": "2023-11-27T17:21:03.617400Z"
    }
   },
   "outputs": [],
   "source": [
    "Train_img = []\n",
    "y_train = []\n",
    "Arch_Train_1 = os.listdir(url_img+\"Train_img/1/\")\n",
    "Arch_Train_0 = os.listdir(url_img+\"Train_img/0/\")\n",
    "\n",
    "for img in Arch_Train_1:\n",
    "    Img = cv2.imread(url_img+\"Train_img/1/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_train.append(1)\n",
    "    Train_img.append(Img)\n",
    "    \n",
    "for img in Arch_Train_0:\n",
    "    Img = cv2.imread(url_img+\"Train_img/0/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_train.append(0)\n",
    "    Train_img.append(Img)\n",
    "    \n",
    "Val_img = []\n",
    "y_val = []\n",
    "Arch_Val_1 = os.listdir(url_img+\"Val_img/1/\")\n",
    "Arch_Val_0 = os.listdir(url_img+\"Val_img/0/\")\n",
    "\n",
    "for img in Arch_Val_1:\n",
    "    Img = cv2.imread(url_img+\"Val_img/1/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_val.append(1)\n",
    "    Val_img.append(Img)\n",
    "    \n",
    "for img in Arch_Val_0:\n",
    "    Img = cv2.imread(url_img+\"Val_img/0/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_val.append(0)\n",
    "    Val_img.append(Img)\n",
    "    \n",
    "Test_img = []\n",
    "y_test = []\n",
    "Arch_Test_1 = os.listdir(url_img+\"Test_img/1/\")\n",
    "Arch_Test_0 = os.listdir(url_img+\"Test_img/0/\")\n",
    "\n",
    "for img in Arch_Test_1:\n",
    "    Img = cv2.imread(url_img+\"Test_img/1/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_test.append(1)\n",
    "    Test_img.append(Img)\n",
    "    \n",
    "for img in Arch_Test_0:\n",
    "    Img = cv2.imread(url_img+\"Test_img/0/\"+img,cv2.IMREAD_GRAYSCALE).astype(np.float32)/255\n",
    "    y_test.append(0)\n",
    "    Test_img.append(Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:22:15.071338Z",
     "iopub.status.busy": "2023-11-27T17:22:15.070982Z",
     "iopub.status.idle": "2023-11-27T17:22:18.070250Z",
     "shell.execute_reply": "2023-11-27T17:22:18.069308Z",
     "shell.execute_reply.started": "2023-11-27T17:22:15.071312Z"
    }
   },
   "outputs": [],
   "source": [
    "Matriz_1 = np.ones((236,446))\n",
    "\n",
    "Train_img = Matriz_1 - np.array(Train_img)\n",
    "Val_img = Matriz_1 - np.array(Val_img)\n",
    "Test_img = Matriz_1 - np.array(Test_img)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:23:09.788131Z",
     "iopub.status.busy": "2023-11-27T17:23:09.787613Z",
     "iopub.status.idle": "2023-11-27T17:23:09.793368Z",
     "shell.execute_reply": "2023-11-27T17:23:09.792407Z",
     "shell.execute_reply.started": "2023-11-27T17:23:09.788097Z"
    }
   },
   "outputs": [],
   "source": [
    "Train_img = Train_img.reshape((len(Train_img),236,446,1))\n",
    "Val_img = Val_img.reshape((len(Val_img),236,446,1))\n",
    "Test_img = Test_img.reshape((len(Test_img),236,446,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:23:14.052270Z",
     "iopub.status.busy": "2023-11-27T17:23:14.051924Z",
     "iopub.status.idle": "2023-11-27T17:23:14.331158Z",
     "shell.execute_reply": "2023-11-27T17:23:14.330205Z",
     "shell.execute_reply.started": "2023-11-27T17:23:14.052244Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Train_img[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T18:34:00.588763Z",
     "iopub.status.busy": "2023-11-27T18:34:00.587977Z",
     "iopub.status.idle": "2023-11-27T18:34:00.793767Z",
     "shell.execute_reply": "2023-11-27T18:34:00.792959Z",
     "shell.execute_reply.started": "2023-11-27T18:34:00.588726Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', strides=1,padding=\"same\", input_shape=(236,446,1)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu',strides=1,padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T18:34:03.128243Z",
     "iopub.status.busy": "2023-11-27T18:34:03.127524Z",
     "iopub.status.idle": "2023-11-27T18:34:03.134253Z",
     "shell.execute_reply": "2023-11-27T18:34:03.133209Z",
     "shell.execute_reply.started": "2023-11-27T18:34:03.128206Z"
    }
   },
   "outputs": [],
   "source": [
    "#CallBack para detener entrenamiento\n",
    "class MNIST_Callback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # método dentro de la clase myCallback, heredada de la clase Callback de keras\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.985):\n",
    "            print(\"\\nSe alcanzó un 98.5% de precisión en la validación! Cancelando Entrenamiento...\")\n",
    "            self.model.stop_training = True\n",
    "        elif(logs.get('accuracy')>0.9):\n",
    "            print(\"\\nSe alcanzó un 90.0% de precisión en el entrenaminto! Cancelando Entrenamiento...\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# crea una instancia de clase\n",
    "accu_callback = MNIST_Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T18:34:05.447572Z",
     "iopub.status.busy": "2023-11-27T18:34:05.447183Z",
     "iopub.status.idle": "2023-11-27T18:34:05.460002Z",
     "shell.execute_reply": "2023-11-27T18:34:05.458960Z",
     "shell.execute_reply.started": "2023-11-27T18:34:05.447537Z"
    }
   },
   "outputs": [],
   "source": [
    "#Compilador del modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T18:34:07.607415Z",
     "iopub.status.busy": "2023-11-27T18:34:07.606712Z",
     "iopub.status.idle": "2023-11-27T18:34:07.664658Z",
     "shell.execute_reply": "2023-11-27T18:34:07.663747Z",
     "shell.execute_reply.started": "2023-11-27T18:34:07.607382Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T18:34:11.299795Z",
     "iopub.status.busy": "2023-11-27T18:34:11.298860Z",
     "iopub.status.idle": "2023-11-27T18:34:26.003432Z",
     "shell.execute_reply": "2023-11-27T18:34:26.002161Z",
     "shell.execute_reply.started": "2023-11-27T18:34:11.299755Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(Train_img, y_train, \n",
    "                    epochs=60,\n",
    "                    validation_data = (Val_img,y_val),\n",
    "                    batch_size=16,\n",
    "                    callbacks=[accu_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(url+'Conv.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4066629,
     "sourceId": 7063318,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
